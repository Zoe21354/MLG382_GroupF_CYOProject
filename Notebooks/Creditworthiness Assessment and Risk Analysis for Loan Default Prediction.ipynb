{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Details**\n",
    "**Title:** CYO Project\n",
    "\n",
    "**Due Date:** 13 May 2024\n",
    "\n",
    "**Contributors:**\n",
    "- Dineo Mogale (576500) \n",
    "- Ewan Morris (577388)\n",
    "- Marcus Mahlatjie (577296)\n",
    "- Tiaan Kritzinger (577643)\n",
    "- Quinton Crouse (577696)\n",
    "- Zoë Treutens (577989)\n",
    "\n",
    "**GitHub Link:** https://github.com/Zoe21354/MLG382_GroupF_CYOProject.git\n",
    "\n",
    "==================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creditworthiness Assessment and Risk Analysis for Loan Default Prediction**\n",
    "This project is a comprehensive study aimed at **building a predictive model to assess the creditworthiness of individuals or businesses**. The purpose of this project is to predict the risk of default on loans or credit lines, which is a critical aspect of financial risk assessment.\n",
    "\n",
    "The project utilizes a dataset titled “Credit Risk Assessment” authored by Urvish Vekariya and sourced from Kaggle. The dataset will undergo a series of data analysis and preprocessing steps, including dataset analysis, univariate and bi-variate analysis, handling missing values, removing duplicates, and outlier value handling. Two models will be built and their predictions will be evaluated. The feature importance from each model will be analyzed and the models will be saved as pickle files for future use. The second model will undergo additional cross-validation to ensure its robustness.\n",
    "\n",
    "Finally, the validated model will be deployed as a server in a web application using DASH, providing a practical interface for credit risk assessment. This project is a significant step towards leveraging machine learning for effective and efficient credit risk management. It aims to provide a reliable tool for financial institutions to make informed decisions regarding loan approvals and credit line extensions.\n",
    "\n",
    "\n",
    "\n",
    "This notebook will take the following structure:\n",
    "\n",
    "    1. Prepare Data (Data Analysis)\n",
    "        A. Dataset Analysis\n",
    "        B. Univariate Analysis\n",
    "        C. Bi-variate Analysis\n",
    "    2. Hypotheses\n",
    "    3. Preprocess Data (Data Cleaning)\n",
    "        A. Handling missing values\n",
    "        B. Removing duplicates\n",
    "        C. Outlier value Handling\n",
    "    4. Split Dataset\n",
    "    5. Model 1\n",
    "        A. Build Model\n",
    "        B. Predictions of the Model\n",
    "        C. Feature Importance from the Model\n",
    "        D. Create Pickle File\n",
    "    6. Model 2\n",
    "        A. Build Model\n",
    "        B. Predictions of the Model\n",
    "        C. Feature Importance from the Model\n",
    "        D. Cross Validation Models\n",
    "        E. Create Pickle File\n",
    "    7. Validate Model 2\n",
    "    8. Web Application\n",
    "\n",
    "===================================================================================\n",
    "\n",
    "# **1. Prepare Data**\n",
    "Before any coding can take place, certain libraries in python need to be imported to perform different functions and make various features available for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import csv                                              # Read and Write to CSV files\n",
    "import pandas as pd                                     # Manipulation and analysis of data\n",
    "import numpy as np                                      # Mathematical operations\n",
    "import matplotlib.pyplot as plt                         # Matplotlib and Seaborn is used to create visual graphs\n",
    "import seaborn as sns                                   \n",
    "from sklearn.model_selection import train_test_split    # Splits the raw_data into two sets of data\n",
    "import warnings                                         # Ignores any future warnings\n",
    "warnings.filterwarnings('ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV files named credit_risk_raw_data and credit_risk_validation_data are read so that the unclean data contained in these files can be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Unclean CSV Files\n",
    "raw_data = pd.read_csv('Data/Original Data/credit_risk_raw_data.csv')\n",
    "raw_data_copy = raw_data.copy()\n",
    "\n",
    "validation_data = pd.read_csv('Data/Original Data/validation_data.csv')\n",
    "validation_data_copy = validation_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A. DATA ANALYSIS PROCESSES**\n",
    "## 1. Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Attributes:\n",
    "print(f\"Raw Data Columns: {raw_data_copy.columns}\\n\")\n",
    "print(f\"Validation Data Columns:{validation_data_copy.columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***\n",
    "- The attribute names are inconsistent and will need standardizing in the data processing section.\n",
    "- Feature Variable (Independent variable): This variable stands alone and is not changed by other variables that are being measured. It is denoted as X in ML algorithms.\n",
    "- Target Variable (Dependent variable): This is the variable that is to be predicted. It is often denoted as Y in ML algorithms.\n",
    "- In both datasets there are 10 feature variables but only the raw_data dataset has 1 target variable.\n",
    "- The target variable in the raw_data dataset is the loan_status attribute.\n",
    "- This variable will be predicted using models for the validation_data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Dataset Datatypes:*\n",
    "Attributes can have different data types, such as numerical, categorical, or ordinal. Knowing the data type of each attribute is important because it determines what kind of statistical analysis or data processing is appropriate. Learning the different datatypes for each attribute in both of the datasets will provide insight into the consistance of the datattypes for each specific attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset DataTypes:\n",
    "print(f\"Raw Dataset Datatypes:\\n{raw_data_copy.dtypes}\\n\")\n",
    "print(f\"Validation Dataset Datatypes:\\n{validation_data_copy.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***\n",
    "- There is a discrepancy between the two datasets: the \"person_emp_length\" attribute is of datatype float64 in the raw_data.csv file but of datatype int64 in the validation_data.csv file. \n",
    "- This could lead to potentially issues when modeling, as the model might be expecting the same data type for a given attribute.\n",
    "- This discrepancy will need to be fixed in the data processing section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Dataset Shape:*\n",
    "Knowing the number of rows in your datasets provides you with an idea of the volume of the data available to you. More rows mean more data, which can lead to more robust and reliable models. However, it can also mean more computational resources and time required for processing. On the other hand knowing the number of columns in the dataset informs the user on the number of features (or variables) available. Overall the analysis of the shape of the dataset can help in assessing the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Raw Data Shape:\\n{raw_data_copy.shape}\")\n",
    "print(f\"Validation Data Shape:\\n{validation_data_copy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***\n",
    "- Raw Data Shape: 1498 rows and 10 columns\n",
    "- Validation Data Shape: 470 rows and 9 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Univariate Analysis\n",
    "\n",
    "When there is just one variable in the data it is called univariate analysis. \n",
    "This is the most basic type of data analysis and finds patterns in the data.\n",
    "Analyzing univariate data involves examining:\n",
    "- Frequency of data\n",
    "- Mean, mode, median, and range\n",
    "\n",
    "## Frequency and Bar charts of each Independent variable and the Dependant variable:\n",
    "- Get the count for each category in the variable\n",
    "- Normalize the data to get the proportion of the different categories in the variable (each count is divided by the total number of values)\n",
    "- Plot a bar chart to visually display the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dependent variable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = raw_data_copy['loan_status'].value_counts(normalize = True)\n",
    "chart = count.plot.bar(title = 'Loan Status', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 2)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- 0.66 or 66% of the people were approved for a loan (i.e Loan_Status = Yes)\n",
    "- 0.34 or 34% of the people were not approved for a loan (i.e Loan_Status = No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Independent variable (Ordinal)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person_age\n",
    "count = raw_data_copy['person_age'].value_counts('normalize = True')\n",
    "chart = count.plot.bar(title='Age', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 3)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The age group ranges from early 20s to 50s\n",
    "- With the largest number of people being of age 22 to 24\n",
    "- There are outlier ages that need to be addressed in the processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person_emp_length\n",
    "count =raw_data_copy['person_emp_length'].value_counts('normalize = True')\n",
    "chart = count.plot.bar(title='Employment Length', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 3)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The most common employment length is less than a year, suggesting a high turnover rate or many short-term positions.\n",
    "- There is a noticeable trend of decreasing frequency as employment length increases, showing that longer tenures are less common.\n",
    "- Overall, the graph sheds light on the dynamics of the workforce, particularly in terms of employment longevity and the distribution of tenure lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cb_person_cred_hist_length\n",
    "count =raw_data_copy['cb_person_cred_hist_length'].value_counts('normalize = True')\n",
    "chart = count.plot.bar(title='Credit History Length', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 3)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The distribution appears to be right-skewed, meaning there are more individuals with shorter credit histories than those with longer ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person_home_ownership\n",
    "count =raw_data_copy['person_home_ownership'].value_counts('normalize = True')\n",
    "chart = count.plot.bar(title='Home Ownership', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 3)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- 57.5% of the people who apply for a loan pay rent\n",
    "- 35.3% of the people who apply for a loan pay a mortgage\n",
    "- 6.9% of the people who apply for a loan own a house\n",
    "- 0.3% of the people who apply for a loan have other living arrangements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loan_intent\n",
    "count =raw_data_copy['loan_intent'].value_counts('normalize = True')\n",
    "chart = count.plot.bar(title='Loan Intent', xlabel = 'Categories', ylabel = 'Frequency')\n",
    "for i, v in enumerate(count):\n",
    "    chart.text(i, v + 0.01, str(round(v, 3)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- 19.6% of the people apply for a loan for their Education\n",
    "- 19.4% of the people apply for a loan for their Medical bills\n",
    "- 17.0% of the people apply for a loan for their Debt Consolidations\n",
    "- 16.5% of the people apply for a loan for Personal reason\n",
    "- 15.9% of the people apply for a loan for Venture funding\n",
    "- 11.7% of the people apply for a loan for Home Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Independent Variable (Nominal)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loan_percent_income\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "raw_data_copy.dropna()\n",
    "sns.distplot(raw_data_copy['loan_percent_income'])\n",
    "plt.title('Distribution of Loan Income Percentage')\n",
    "plt.xlabel('Loan Income Percentage')\n",
    "plt.ylabel('Density')\n",
    "plt.subplot(122)\n",
    "boxplot =raw_data_copy['loan_percent_income'].plot.box()\n",
    "boxplot.set_title('Box Plot of Loan Income Percentage')\n",
    "boxplot.set_xlabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The distribution graph shows a right-skewed distribution, indicating most loan income percentages are low, with fewer high values.\n",
    "- The box plot reveals the quartiles of the data and potential outliers above the upper whisker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loan_int_rate\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "raw_data_copy.dropna()\n",
    "sns.distplot(raw_data_copy['loan_int_rate'])\n",
    "plt.title('Distribution of Loan Interest Rate')\n",
    "plt.xlabel('Loan Rate')\n",
    "plt.ylabel('Density')\n",
    "plt.subplot(122)\n",
    "boxplot =raw_data_copy['loan_int_rate'].plot.box()\n",
    "boxplot.set_title('Box Plot of Loan Interest Rate')\n",
    "boxplot.set_xlabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The distribution graph shows a right-skewed distribution of loan rates, with the majority of values clustered between 5% and 10%.\n",
    "- The box plot indicates the median rate at around 10%, with half of the rates falling between approximately 7.5% and 12.5%. \n",
    "- The box plot indicates that outliers are present above the upper whisker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person_income\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "raw_data_copy.dropna()\n",
    "sns.distplot(raw_data_copy['person_income'])\n",
    "plt.title('Distribution of Income')\n",
    "plt.xlabel('Loan Rate')\n",
    "plt.ylabel('Density')\n",
    "plt.subplot(122)\n",
    "boxplot =raw_data_copy['person_income'].plot.box()\n",
    "boxplot.set_title('Box Plot of Income')\n",
    "boxplot.set_xlabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The distribution graph indicates a peak near zero with a long tail, suggesting a large number of individuals with low income and fewer with high income, reflecting economic inequality.\n",
    "- The box plot shows there are  outliers indicating individuals with significantly higher incomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loan_amnt\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "raw_data_copy.dropna()\n",
    "sns.distplot(raw_data_copy['loan_amnt'])\n",
    "plt.title('Distribution of Loan Amount')\n",
    "plt.xlabel('Loan Rate')\n",
    "plt.ylabel('Density')\n",
    "plt.subplot(122)\n",
    "boxplot =raw_data_copy['loan_amnt'].plot.box()\n",
    "boxplot.set_title('Box Plot of Loan Amount')\n",
    "boxplot.set_xlabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The distribution graph shows a right-skewed distribution with a majority of the loans being of lower amounts, indicating that smaller loans are more common.\n",
    "- The box plot shows that their are outliers of loans significantly larger than the majority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bi-variate Analysis\n",
    "- When there are two variables in the data it is called bi-variate analysis. \n",
    "- Data is analyzed to find the relationship between the dependent and independent variables.\n",
    "- Analyzing bi-variate data involves the following techniques:\n",
    "    - Scatter plots and stacked bar graphs\n",
    "    - Correlation Coefficients\n",
    "    - Covariance matrices\n",
    "- The graphs created below will display how the Dependent Attribute ‘loan_status’ is distributed within each Independent Attribute, regardless of how many observations there are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ordinal Independent Variables and Dependent Variable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs person_age\n",
    "person_age = pd.crosstab(raw_data_copy['person_age'], raw_data_copy['loan_status'])\n",
    "person_age.div(person_age.sum(1).astype(float),axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Loan Status by Age Category')\n",
    "plt.xlabel('Age Categories')\n",
    "plt.ylabel('Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- Individuals with the age group of 20 have all been aproved for a loan where as individuals of age 49 have all been rejected. \n",
    "- These are significant\n",
    "- The graph suggests that age is a significant factor in loan approval decisions by lenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs person_home_ownership\n",
    "person_home_ownership = pd.crosstab(raw_data_copy['person_home_ownership'], raw_data_copy['loan_status'])\n",
    "person_home_ownership.div(person_home_ownership.sum(1).astype(float),axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Loan Status by Home Ownership Category')\n",
    "plt.xlabel('Home Ownership Categories')\n",
    "plt.ylabel('Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs person_emp_length\n",
    "person_emp_length = pd.crosstab(raw_data_copy['person_emp_length'], raw_data_copy['loan_status'])\n",
    "person_emp_length.div(person_emp_length.sum(1).astype(float),axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Loan Status by Employment Length Category')\n",
    "plt.xlabel('Employment Length Categories')\n",
    "plt.ylabel('Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insight Gained:***\n",
    "- The proportions of loans that are fully paid or charged off are relatively consistent across all employment length categories.\n",
    "- Employment length does not appear to be a strong indicator of loan repayment behavior, as there is no significant difference in loan status distribution among the categories.\n",
    "- The graph suggests that factors other than employment length might be more influential in determining whether a loan will be fully paid or charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_intent = pd.crosstab(raw_data_copy['loan_intent'], raw_data_copy['loan_status'])\n",
    "loan_intent.div(loan_intent.sum(1).astype(float),axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Loan Status by Loan Intent Category')\n",
    "plt.xlabel('Loan Intent Categories')\n",
    "plt.ylabel('Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs cb_person_cred_hist_length\n",
    "cb_person_cred_hist_length = pd.crosstab(raw_data_copy['cb_person_cred_hist_length'], raw_data_copy['loan_status'])\n",
    "cb_person_cred_hist_length.div(cb_person_cred_hist_length.sum(1).astype(float),axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Loan Status by Credit History Length Category')\n",
    "plt.xlabel('Credit History Length Categories')\n",
    "plt.ylabel('Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Numerical Independent Variables and Dependent Variable LoanAmount__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs loan_percent_income\n",
    "low = raw_data_copy['loan_percent_income'].quantile(0.333) # 33.3th percentile\n",
    "average = raw_data_copy['loan_percent_income'].quantile(0.666) # 66.6th percentile\n",
    "high = 0.6\n",
    "\n",
    "bins = [0, low, average, high]\n",
    "group=['Low','Average','High']\n",
    "\n",
    "raw_data_copy['loan_percent_income_bin']=pd.cut(raw_data_copy['loan_percent_income'],bins,labels=group)\n",
    "loan_percent_income_bin=pd.crosstab(raw_data_copy['loan_percent_income_bin'],raw_data_copy['loan_status'])\n",
    "loan_percent_income_bin.div(loan_percent_income_bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.title('Percentage of Loan Income Percentage Per Income Bracket')\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs loan_int_rate\n",
    "low = raw_data_copy['loan_int_rate'].quantile(0.333) # 33.3th percentile\n",
    "average = raw_data_copy['loan_int_rate'].quantile(0.666) # 66.6th percentile\n",
    "high = 22\n",
    "\n",
    "bins = [0, low, average, high]\n",
    "group=['Low','Average','High']\n",
    "\n",
    "raw_data_copy['loan_int_rate_bin']=pd.cut(raw_data_copy['loan_int_rate'],bins,labels=group)\n",
    "loan_int_rate_bin=pd.crosstab(raw_data_copy['loan_int_rate_bin'],raw_data_copy['loan_status'])\n",
    "loan_int_rate_bin.div(loan_int_rate_bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.title('Percentage of Loan Interest Rate Per Interest Bracket')\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs loan_amnt\n",
    "low = raw_data_copy['loan_amnt'].quantile(0.25) # 25th percentile\n",
    "average = raw_data_copy['loan_amnt'].quantile(0.50) # 50th percentile\n",
    "above_average = raw_data_copy['loan_amnt'].quantile(0.75) # 75th percentile\n",
    "veryHigh = raw_data_copy['loan_amnt'].max() + 1 # maximum loan amount plus 1\n",
    "\n",
    "bins = [0, low, average, above_average, veryHigh]\n",
    "group=['Low','Average','High', 'Very High']\n",
    "\n",
    "raw_data_copy['loan_amnt_bin'] = pd.cut(raw_data_copy['loan_amnt'], bins, labels=group)\n",
    "loan_amnt_bin = pd.crosstab(raw_data_copy['loan_amnt_bin'], raw_data_copy['loan_status'])\n",
    "loan_amnt_bin.div(loan_amnt_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Percentage of Loan Amount Per Loan Brackets')\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Insights Gained:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Status vs person_income\n",
    "low = raw_data_copy['person_income'].quantile(0.25) # 25th percentile\n",
    "average = raw_data_copy['person_income'].quantile(0.50) # 50th percentile\n",
    "above_average = raw_data_copy['person_income'].quantile(0.75) # 75th percentile\n",
    "veryHigh = raw_data_copy['person_income'].max()+ 1 \n",
    "\n",
    "bins = [0, low, average, above_average, veryHigh]\n",
    "group=['Low','Average','Above Average', 'Very High']\n",
    "\n",
    "raw_data_copy['person_income_bin'] = pd.cut(raw_data_copy['person_income'], bins, labels=group)\n",
    "person_income_bin = pd.crosstab(raw_data_copy['person_income_bin'], raw_data_copy['loan_status'])\n",
    "person_income_bin.div(person_income_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Percentage of Income Per Income Bracket')\n",
    "plt.xlabel('Person Income')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all bins created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_copy=raw_data_copy.drop(['loan_percent_income_bin', 'loan_int_rate_bin', 'loan_amnt_bin', 'person_income_bin'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Heatmap, the numerical attributes in the dataset is viewed to gain insight into the overall comparison through the colour shade variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = raw_data_copy.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(numeric_cols.corr(), annot=True, cmap='PuRd')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight Gained:\n",
    "- ‘person_age’ and ‘person_income’ have a dark red cell at their intersection, it means they are strongly positively correlated. As one increases, the other also tends to increase.\n",
    "- ‘person_age’ and ‘loan_intent’ have a dark purple cell at their intersection, it means they are strongly negatively correlated. As one increases, the other tends to decrease.\n",
    "- ‘person_weight’ and ‘person_income’, ‘loan_amount’ and ‘person_home_ownership’, ‘loan_intent’ and ‘loan_percent_income’ all have weak or no correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having now seen how the different attributes impact the outcome in our datasets, several hypotheses can be drawn from the results.\n",
    "\n",
    "===================================================================================\n",
    "# **2. Hypotheses**\n",
    "\n",
    "- __Hypothesis 1__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 2__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 3__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 4__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 5__: \n",
    "    - Justification: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **3. Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **4. Split Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **5. Model 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **6. Model 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **7. Validate Model 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **8. Web Application**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
