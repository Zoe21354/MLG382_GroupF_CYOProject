{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Details**\n",
    "**Title:** CYO Project\n",
    "\n",
    "**Due Date:** 13 May 2024\n",
    "\n",
    "**Contributors:**\n",
    "- Dineo Mogale (576500) \n",
    "- Ewan Morris (577388)\n",
    "- Marcus Mahlatjie (577296)\n",
    "- Tiaan Kritzinger (577643)\n",
    "- Quinton Crouse (577696)\n",
    "- Zoë Treutens (577989)\n",
    "\n",
    "**GitHub Link:**\n",
    "\n",
    "==================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creditworthiness Assessment and Risk Analysis for Loan Default Prediction\n",
    "This project is a comprehensive study aimed at building a predictive model to assess the creditworthiness of individuals or businesses. The purpose of this project is to predict the risk of default on loans or credit lines, which is a critical aspect of financial risk assessment.\n",
    "\n",
    "The project utilizes a dataset titled “Credit Risk Assessment” authored by Urvish Vekariya and sourced from Kaggle. The dataset will undergo a series of data analysis and preprocessing steps, including dataset analysis, univariate and bi-variate analysis, handling missing values, removing duplicates, and outlier value handling. Two models will be built and their predictions will be evaluated. The feature importance from each model will be analyzed and the models will be saved as pickle files for future use. The second model will undergo additional cross-validation to ensure its robustness.\n",
    "\n",
    "Finally, the validated model will be deployed as a server in a web application using DASH, providing a practical interface for credit risk assessment. This project is a significant step towards leveraging machine learning for effective and efficient credit risk management. It aims to provide a reliable tool for financial institutions to make informed decisions regarding loan approvals and credit line extensions.\n",
    "\n",
    "\n",
    "\n",
    "This notebook will take the following structure:\n",
    "\n",
    "    1. Prepare Data (Data Analysis)\n",
    "        A. Dataset Analysis\n",
    "        B. Univariate Analysis\n",
    "        C. Bi-variate Analysis\n",
    "    2. Hypotheses\n",
    "    3. Preprocess Data (Data Cleaning)\n",
    "        A. Handling missing values\n",
    "        B. Removing duplicates\n",
    "        C. Outlier value Handling\n",
    "    4. Split Dataset\n",
    "    5. Model 1\n",
    "        A. Build Model\n",
    "        B. Predictions of the Model\n",
    "        C. Feature Importance from the Model\n",
    "        D. Create Pickle File\n",
    "    6. Model 2\n",
    "        A. Build Model\n",
    "        B. Predictions of the Model\n",
    "        C. Feature Importance from the Model\n",
    "        D. Cross Validation Models\n",
    "        E. Create Pickle File\n",
    "    7. Validate Model 2\n",
    "    8. Web Application\n",
    "\n",
    "===================================================================================\n",
    "\n",
    "# **1. Prepare Data**\n",
    "Before any coding can take place, certain libraries in python need to be imported to perform different functions and make various features available for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having now seen how the different attributes impact the outcome in our datasets, several hypotheses can be drawn from the results.\n",
    "\n",
    "===================================================================================\n",
    "# **2. Hypotheses**\n",
    "\n",
    "- __Hypothesis 1__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 2__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 3__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 4__: \n",
    "    - Justification: \n",
    "\n",
    "- __Hypothesis 5__: \n",
    "    - Justification: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **3. Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **4. Split Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **5. Model 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **6. Model 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **7. Validate Model 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================\n",
    "\n",
    "# **8. Web Application**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
